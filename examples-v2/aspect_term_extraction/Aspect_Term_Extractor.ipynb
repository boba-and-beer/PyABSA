{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# This is the tutorials of using PyABSA for aspect term extraction\n",
    "Drafted for v2.0 and higher versions. Note there are many breaking changes in v2.0, so you do not need to upgrade to v2.0 and higher versions if you are using code, API, checkpoints, datasets or anything from v1.0. Let's begin the introduction."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install pyabsa >= 2.0.0\n",
    "from pyabsa import AspectTermExtraction as ATEPC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ATEPCModelList\n",
    "There are three types of APC models for aspect term extraction, which are based on the local context focus mechanism\n",
    "Notice: when you select to use a model, please make sure to carefully manage the configurations, e.g., for glove-based models, you need to set hidden dim and embed_dim manually.\n",
    "We already provide some pre-defined configurations. Refer to the source code if you have any question\n",
    "e.g.,"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# config = ATEPC.ATEPCConfigManager.get_atepc_config_glove()  # get pre-defined configuration for GloVe model, the default embed_dim=300\n",
    "config = ATEPC.ATEPCConfigManager.get_atepc_config_english()  # this config contains 'pretrained_bert', it is based on pretrained models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# ATEPCDatasetList\n",
    "There are the [datasets](https://github.com/yangheng95/ABSADatasets) from publication or third-party contribution. There dataset can be downloaded and processed automatically.\n",
    "In pyabsa, you can pass a set of datasets to train a model.\n",
    "e.g., for using integrated datasets:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyabsa import DatasetItem\n",
    "\n",
    "dataset = ATEPC.ATEPCDatasetList.SemEval\n",
    "# now the dataset is a DatasetItem object, which has a name and a list of subdatasets\n",
    "# dataset contains Laptop14, Restaurant14, Restaurant16 datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can use your own dataset provided that it is formatted according to [ABSADatasets](https://github.com/yangheng95/ABSADatasets#important-rename-your-dataset-filename-before-use-it-in-pyabsa)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Put your dataset into integrated_datasets folder, it this folder does not exist, you need to call:\n",
    "# from pyabsa import download_all_available_datasets\n",
    "# download_all_available_datasets()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "to pass datasets to PyABSA trainers, you can"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_dataset = DatasetItem('my_dataset', ['my_dataset1', 'my_dataset2'])\n",
    "# my_dataset1 and my_dataset2 are the dataset folders. In there folders, the train dataset is necessary\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training\n",
    "Let's prepare to train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyabsa import ModelSaveOption, DeviceTypeOption\n",
    "\n",
    "trainer = ATEPC.ATEPCTrainer(\n",
    "    config=config,\n",
    "    dataset=dataset,\n",
    "    from_checkpoint=None,\n",
    "    # if you want to resume training from our pretrained checkpoints, you can pass the checkpoint name here\n",
    "    auto_device=DeviceTypeOption.AUTO,\n",
    "    path_to_save=None,  # set a path to save checkpoints, if it is None, save checkpoints at 'checkpoints' folder\n",
    "    checkpoint_save_mode=ModelSaveOption.SAVE_MODEL_STATE_DICT,\n",
    "    load_aug=False,\n",
    "    # there are some augmentation dataset for integrated datasets, you use them by setting load_aug=True to improve performance\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "to load trained model for inference:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sentiment_classifier = trainer.load_trained_model()\n",
    "assert isinstance(sentiment_classifier, ATEPC.AspectExtractor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Use our checkpoints to initialize a SentimentClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyabsa import available_checkpoints\n",
    "ckpts = available_checkpoints()\n",
    "# find a suitable checkpoint and use the name:\n",
    "aspect_extractor = ATEPC.AspectExtractor(checkpoint='english')  # here I use the english checkpoint which is trained on all English datasets in PyABSA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple Prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "atepc_examples = ['But the staff was so nice to us .',\n",
    "                  'But the staff was so horrible to us .',\n",
    "                  r'Not only was the food outstanding , but the little ` perks \\' were great .',\n",
    "                  'It took half an hour to get our check , which was perfect since we could sit , have drinks and talk !',\n",
    "                  'It was pleasantly uncrowded , the service was delightful , the garden adorable , '\n",
    "                  'the food -LRB- from appetizers to entrees -RRB- was delectable .',\n",
    "                  'How pretentious and inappropriate for MJ Grill to claim that it provides power lunch and dinners !'\n",
    "                  ]\n",
    "\n",
    "for ex in atepc_examples:\n",
    "    aspect_extractor.predict(\n",
    "        text=ex,\n",
    "        print_result=True,\n",
    "        ignore_error=True,  # ignore an invalid example, if it is False, invalid examples will raise Exceptions\n",
    "        eval_batch_size=32\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Batch Inference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sentiment_classifier.batch_predict(\n",
    "    inference_source=None,\n",
    "    print_result=True,\n",
    "    save_result=False,\n",
    "    ignore_error=True,\n",
    "    eval_batch_size=32\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Annotate your own datasets via PyABSA\n",
    "[Auto-Annotation](https://github.com/yangheng95/ABSADatasets#auto-annoate-your-datasets-via-pyabsa)  # available for v1.0 currently\n",
    "[Manually-Annotation](https://github.com/yangheng95/ABSADatasets/tree/v1.2/DPT)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Deploy a ATEPC demo\n",
    "TBC ...\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
